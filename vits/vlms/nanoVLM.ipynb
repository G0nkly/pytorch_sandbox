{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfLX+GiWv8xV2LVjvM8L/5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/G0nkly/pytorch_sandbox/blob/main/vits/vlms/nanoVLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "diXQ9DkumHGB"
      },
      "outputs": [],
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math, random\n",
        "import numpy as np\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "rbUm1X6rmtnP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Variables"
      ],
      "metadata": {
        "id": "kCIgz0QonaSf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "IMG_SIZE = 32\n",
        "EMBED_DIM = 64\n",
        "ATTENTION_HEADS = 4\n",
        "BATCH_SIZE = 12\n",
        "EPOCHS = 10\n",
        "LR = 3e-4\n",
        "TEMPERATURE = 0.07"
      ],
      "metadata": {
        "id": "um56Y6_FnMlH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Synthetic Dataset"
      ],
      "metadata": {
        "id": "UOcHtWXxnbju"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colors = [\"red\", \"green\", \"blue\", \"yellow\", \"purple\", \"orange\", \"pink\", \"brown\", \"gray\"]\n",
        "shapes = [\"square\", \"circle\", \"triangle\"]\n",
        "positions = [\"left\", \"center\", \"right\", \"top\", \"bottom\", \"top-left\", \"top-right\", \"bottom-left\", \"bottom-right\"]"
      ],
      "metadata": {
        "id": "GwhfZ_B5n4Tc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Drawing image shapes"
      ],
      "metadata": {
        "id": "YG9gOPgsoXHB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_sample(color, shape, position, img_size=IMG_SIZE):\n",
        "  img = Image.new(\"RGB\", (img_size, img_size), \"white\")\n",
        "  draw = ImageDraw.Draw(img)\n",
        "  margin = 6\n",
        "  w = h = img_size - 2 * margin\n",
        "\n",
        "  # Calculate the coordinates\n",
        "  if \"left\" in position:\n",
        "    x0 = margin\n",
        "    x1 = margin + w // 2\n",
        "  elif \"top-left\" in position:\n",
        "    x0 = margin\n",
        "    x1 = margin + w // 2\n",
        "  elif \"bottom-left\" in position:\n",
        "    x0 = margin\n",
        "    x1 = margin + w // 2\n",
        "  elif \"right\" in position:\n",
        "    x0 = margin + w // 2\n",
        "    x1 = img_size - margin\n",
        "  elif \"top-right\" in position:\n",
        "    x0 = margin + w // 2\n",
        "    x1 = img_size - margin\n",
        "  elif \"bottom-right\" in position:\n",
        "    x0 = margin + w // 2\n",
        "    x1 = img_size - margin\n",
        "  else:\n",
        "    x0 = margin + w // 4\n",
        "    x1 = margin + h // 2\n",
        "\n",
        "\n",
        "  # Calculate y coordinates\n",
        "  if \"top\" in position:\n",
        "    y0 = margin\n",
        "    y1 = margin + h // 2\n",
        "  elif \"top-left\" in position:\n",
        "    y0 = margin\n",
        "    y1 = margin + h // 2\n",
        "  elif \"top-right\" in position:\n",
        "    y0 = margin\n",
        "    y1 = margin + h // 2\n",
        "  elif \"bottom\" in position:\n",
        "    y0 = margin + h // 2\n",
        "    y1 = img_size - margin\n",
        "  elif \"bottom-left\" in position:\n",
        "    y0 = margin + h // 2\n",
        "    y1 = img_size - margin\n",
        "  elif \"bottom-right\" in position:\n",
        "    y0 = margin + h // 2\n",
        "    y1 = img_size - margin\n",
        "  else:\n",
        "    y0 = margin + h // 4\n",
        "    y1 = margin + 3 * h // 4\n",
        "\n",
        "  if shape == \"square\":\n",
        "    draw.rectangle([x0, y0, x1, y1], fill=color, outline=\"black\")\n",
        "  elif shape == \"circle\":\n",
        "    draw.ellipse([x0, y0, x1, y1], fill=color, outline=\"black\")\n",
        "  else:\n",
        "    draw.polygon([((x1+x0)//2, y0), (x0, y1), (x1, y1)], fill=color, outline=\"black\")\n",
        "\n",
        "  return img\n",
        "\n"
      ],
      "metadata": {
        "id": "2MgQE8dnoaGy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Class for building the dataset"
      ],
      "metadata": {
        "id": "xExlhdpqsq0u"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ShapesDataset():\n",
        "  def __init__(self):\n",
        "    self.images = []\n",
        "    self.captions = []\n",
        "\n",
        "    for c in colors:\n",
        "      for s in shapes:\n",
        "        for p in positions:\n",
        "          img = draw_sample(c, s, p)\n",
        "          cap = f\"{c} {s} {p}\"\n",
        "          self.images.append(torch.from_numpy(np.asarray(img)).permute(2,0,1).float()/255.0)\n",
        "          self.captions.append(cap)\n",
        "\n",
        "    self.vocab, self.word2idx = self.build_vocab(self.captions)\n",
        "\n",
        "  def build_vocab(self, texts):\n",
        "    words = sorted({w for t in texts for w in t.split()})\n",
        "    vocab = [\"[CLS]\"] + words\n",
        "    w2i = {w:i for i,w in enumerate(vocab)}\n",
        "    return vocab, w2i\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def encode_text(self, text):\n",
        "    toks = [self.word2idx[\"[CLS]\"]] + [self.word2idx[w] for w in text.split()]\n",
        "    return torch.tensor(toks, dtype=torch.long)\n",
        "\n",
        "  def __getitem__(self,  idx):\n",
        "    return self.images[idx], self.encode_text(self.captions[idx])"
      ],
      "metadata": {
        "id": "pHAkBat_soYD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create Dataset"
      ],
      "metadata": {
        "id": "uJmkqMW0c5RC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_ds = ShapesDataset()\n",
        "VOCAB_SIZE = len(full_ds.vocab)\n",
        "print(VOCAB_SIZE)\n",
        "print(full_ds.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cldBZB8YeCMc",
        "outputId": "f8c3064e-f025-4d91-e907-11c479366015"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n",
            "['[CLS]', 'blue', 'bottom', 'bottom-left', 'bottom-right', 'brown', 'center', 'circle', 'gray', 'green', 'left', 'orange', 'pink', 'purple', 'red', 'right', 'square', 'top', 'top-left', 'top-right', 'triangle', 'yellow']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3026023183.py:11: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:206.)\n",
            "  self.images.append(torch.from_numpy(np.asarray(img)).permute(2,0,1).float()/255.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Train - Val data creation"
      ],
      "metadata": {
        "id": "2HQlSTvMeJHN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * len(full_ds))\n",
        "val_size = len(full_ds) - train_size\n",
        "train_ds, val_ds = torch.utils.data.random_split(full_ds, [train_size, val_size])"
      ],
      "metadata": {
        "id": "Sj73IfZXzcIG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Dataloader"
      ],
      "metadata": {
        "id": "rSqDpsIVzhRg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "BrttDOcl0xpM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Display a simple data point"
      ],
      "metadata": {
        "id": "tVq8VDTc1FgL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs, encoded_caps = next(iter(train_loader))\n",
        "idx = random.randint(0, len(imgs) - 1)\n",
        "img = (imgs[idx].permute(1,2,0).numpy() * 255).astype(np.uint8) # Convert to displayable image\n",
        "\n",
        "# Decode the caption\n",
        "caption_tokens = encoded_caps[idx].tolist()\n",
        "caption = \"\".join([full_ds.vocab[token] for token in caption_tokens if token in range(len(full_ds.vocab))])\n",
        "# Remove the [CLS] token from the displayed caption\n",
        "caption = caption.replace(\"[CLS]\", \"\")\n",
        "\n",
        "plt.figure(figsize=(2.5, 2.5))\n",
        "plt.imshow(img)\n",
        "plt.title(caption, fontsize=8)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "r5Fptwtt1QzP",
        "outputId": "27393f3a-1a69-4b89-d4a4-32b735035695"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 250x250 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Image Encoder"
      ],
      "metadata": {
        "id": "WhLqAIJ519IS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageEncoder(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.convolutions = nn.Sequential(\n",
        "      nn.Conv2d(3, 32, 3, 2, 1),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(32, 64, 3, 2, 1),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(64, 128, 3, 2, 1),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(128, 256, 3, 2, 1)\n",
        "    )\n",
        "\n",
        "    self.projection = nn.Linear(256, embed_dim)\n",
        "    self.layernorm1 = nn.LayerNorm(embed_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.convolutions(x)\n",
        "    x = x.mean(dim=[2,3])\n",
        "    x = self.projection(x)\n",
        "    x = F.normalize(self.layernorm(x), dim=-1)\n",
        "    return x"
      ],
      "metadata": {
        "id": "djlkDs8Y4yXL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Text Encoder"
      ],
      "metadata": {
        "id": "wnUNAqXMqBWc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}