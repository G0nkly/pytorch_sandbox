{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+kh1bH6X8kwSYPDjrYK9A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/G0nkly/pytorch_sandbox/blob/main/finetuning/Lora.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ao2xvPA7PX1a"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets peft accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"sshleifer/tiny-gpt2\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "FvDv4ZPFP8Ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###############\n",
        "# Custom Data #\n",
        "###############"
      ],
      "metadata": {
        "id": "IwfHPC6XQO4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "texts = [\n",
        "    \"Hello World! This my customm text. \\n\",\n",
        "    \"Today I learned about LoRA and Transformers. \\n\",\n",
        "    \"AI is amazing! \\n\"\n",
        "]\n",
        "\n",
        "dataset = Dataset.from_dict({\"text\": texts})\n",
        "encodings = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "def tokenize(batch):\n",
        "  tokens = tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=64)\n",
        "  tokens[\"labels\"] = tokens[\"input_ids\"]\n",
        "  return tokens\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
        "tokenized_dataset.set_format(\"torch\")"
      ],
      "metadata": {
        "id": "F3RyKbd7U4Kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset[2]"
      ],
      "metadata": {
        "id": "hHLoPtnG1Yqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########\n",
        "# LoRA #\n",
        "########"
      ],
      "metadata": {
        "id": "5AHyJ_ZuVoHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"c_attn\", \"c_proj\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.CAUSAL_LM\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "id": "gn9yGAyPVv6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############\n",
        "# Training #\n",
        "############"
      ],
      "metadata": {
        "id": "kmZwkBvCWNA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./lora-out\",\n",
        "    per_device_train_batch_size=2,\n",
        "    num_train_epochs=10,\n",
        "    learning_rate=2e-4,\n",
        "    save_strategy=\"no\",\n",
        "    fp16=False,\n",
        "    logging_steps=200\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    args=training_args,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "kS0luHPAWRQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##############\n",
        "# Evaluation #\n",
        "##############"
      ],
      "metadata": {
        "id": "dG8KtDgfW4T5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iq4gSDiEW851"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}