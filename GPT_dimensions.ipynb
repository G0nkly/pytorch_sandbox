{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6AtW8GhWiKxwuK/RyxHY8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/G0nkly/pytorch_sandbox/blob/main/GPT_dimensions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "Y1aOJOJ1KCmK"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3qCyCGVskuv4"
      },
      "outputs": [],
      "source": [
        "# Lets look at each of the layers\n",
        "# 1) Encoding\n",
        "# 2) Embedding\n",
        "# 3) Positional Encoding\n",
        "# 4) Attention: key, query, value\n",
        "# 5) Feedforward\n",
        "# 6) Block/Layernorm\n",
        "# 7) Classification / LM Head"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################\n",
        "# DATA EXAMPLE #\n",
        "################\n",
        "\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "\n",
        "with open(mode=\"r\", file=\"input.txt\") as f:\n",
        "  text = f.read()\n",
        "\n",
        "vocab = list(sorted(set(text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaC8pwxBKXVi",
        "outputId": "8248ad5b-adad-4a0f-efdd-28deb76cf700"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-15 07:51:22--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-06-15 07:51:23 (17.7 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##################\n",
        "# HYPERPARAMTERS #\n",
        "##################"
      ],
      "metadata": {
        "id": "QITuTbF7KLJB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 32\n",
        "block_size = 8\n",
        "n_heads = 4"
      ],
      "metadata": {
        "id": "inC3GWsPKQSl"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############\n",
        "# ENCODING #\n",
        "############"
      ],
      "metadata": {
        "id": "KznIrUvIJrAn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {v:k for k,v in enumerate(vocab)}\n",
        "itos = {k:v for k,v in enumerate(vocab)}\n",
        "encode = lambda seq: [stoi[char] for char in seq]\n",
        "decode = lambda numbers: \"\".join([itos[num] for num in numbers])\n",
        "\n",
        "def get_batch(split: str):\n",
        "  dataset = train if split == \"train\" else val"
      ],
      "metadata": {
        "id": "ghD7YPk8HXsr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#############\n",
        "# EMBEDDING #\n",
        "#############"
      ],
      "metadata": {
        "id": "7bf0P7L9Id9u"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)"
      ],
      "metadata": {
        "id": "d0zeDIuzKBgA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor(encode(\"Haubi\"))"
      ],
      "metadata": {
        "id": "HirEowEUODk6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyIOe9_tOMPE",
        "outputId": "f7b7e867-1dae-4ac7-e066-3079f5edcb7c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9273,  0.3304,  0.6638, -0.4366,  0.4378, -0.2666, -0.0975,  0.1392,\n",
              "         -0.0128, -0.0692,  0.5741,  0.4418, -1.3849,  1.0975,  0.5832, -0.9658,\n",
              "         -1.6483, -0.4084,  0.8306, -1.4172,  1.6174, -0.6841, -0.9252, -0.5369,\n",
              "          0.9811,  0.0101, -0.7452,  0.7741,  0.2763, -1.3349, -0.2718, -0.0312],\n",
              "        [-2.2190, -0.3504, -1.6768,  1.9151,  0.4400, -0.1605,  0.4397, -2.0158,\n",
              "         -0.6278,  0.4262,  0.4565, -1.2894,  1.0605, -1.9683, -0.7313,  1.2038,\n",
              "          0.3054, -1.1260,  0.5817,  1.1115,  0.7540, -1.0459,  0.2068, -0.8568,\n",
              "         -0.4302, -1.0945, -0.6069,  0.7064, -1.3334, -1.1765, -2.6555,  0.8990],\n",
              "        [ 0.6363,  0.4486, -1.2197,  1.4263, -0.2736,  0.5772, -0.3240,  0.7389,\n",
              "          0.4402,  1.2262,  0.3455, -0.4795, -0.6717, -0.3513, -1.7074,  0.2935,\n",
              "         -1.6747, -0.1381, -0.6014,  0.8597,  0.8348,  0.7566, -0.8566, -0.8768,\n",
              "         -0.9643, -1.0129,  1.2567,  1.5986,  0.5272, -1.0388, -0.5194,  0.6921],\n",
              "        [-0.7371,  0.6034, -1.7953,  1.4913, -2.8798, -1.3350, -0.8636,  0.7119,\n",
              "         -0.3798,  0.0992, -0.0926,  0.8917,  0.1662, -0.8098, -1.5589,  0.1281,\n",
              "         -0.4015, -1.0420, -0.9674,  0.0650, -1.4192, -0.4437,  1.1380, -0.0386,\n",
              "          0.9445,  0.5310,  0.1077, -0.8702, -1.3707,  0.2425, -1.1024, -0.0219],\n",
              "        [-0.6217, -0.0160, -1.6050, -0.1166,  0.0860, -1.8208, -1.5563,  1.2114,\n",
              "         -1.3789,  0.6065, -0.1548, -1.1730, -1.3442,  1.0032, -0.1178,  0.5207,\n",
              "          1.2521,  0.1283,  1.0576,  0.0931,  0.5145,  0.4642, -0.6350, -0.0468,\n",
              "          1.2288,  1.4110,  0.9066,  0.1950,  0.2545,  0.8155,  2.0104,  1.0717]],\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#########################\n",
        "# POSITIONAL 'ENCODING' #\n",
        "#########################"
      ],
      "metadata": {
        "id": "uEBhtYKQONlj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "postional_embedding = nn.Embedding(num_embeddings=5, embedding_dim=32)"
      ],
      "metadata": {
        "id": "dHmnOaSVPmeS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "postional_embedding(torch.arange(5)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24mQLBiyReS5",
        "outputId": "4aadd4a5-6fea-4948-f761-9b84abc4d472"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_tensor = embedding(t) + postional_embedding(torch.arange(5, dtype=torch.long))\n",
        "embedded_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnBn3VO3RnEw",
        "outputId": "3948ff70-3dd7-4d19-b693-0085b911237c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.5310,  0.2781,  0.3253,  0.6672,  0.9284,  0.3864, -0.1435, -2.7747,\n",
              "         -1.3929, -0.6017,  1.2140, -0.2050, -1.5046,  3.3244,  0.3451, -1.3694,\n",
              "         -0.5394, -2.4792,  0.3771, -1.1443,  0.1556, -0.8633, -0.0871, -1.5353,\n",
              "          0.2487,  0.4565, -0.9097, -0.9768,  1.6561, -1.6015, -2.0356, -0.3675],\n",
              "        [-1.4176,  0.1038, -4.5760,  0.6590,  0.8875,  0.1559,  1.2824, -2.1702,\n",
              "          1.0330,  2.2309,  1.3258, -1.8062,  2.2117, -1.1957, -0.7506,  0.1473,\n",
              "         -1.1387,  0.1314, -0.4494, -0.0161,  0.6809, -1.1862,  0.0420, -1.5893,\n",
              "          0.6788,  0.5010, -0.5437,  0.7290, -1.6392, -1.6903, -3.4132,  1.2522],\n",
              "        [ 0.1742,  0.2318, -0.1092,  2.4308,  0.5409,  0.5441, -1.9386,  0.3867,\n",
              "          1.1274,  0.6398,  0.8996,  0.4444,  0.0757,  0.2784, -1.9436,  1.0691,\n",
              "         -1.5470,  0.9550,  0.2697,  1.8185,  1.8194,  0.8487, -1.3616, -0.9076,\n",
              "         -1.0161, -2.3691, -0.0755,  3.9784, -1.4509, -1.5981, -1.1311, -0.5237],\n",
              "        [-0.9978,  3.2911, -1.7463,  1.4165, -3.5723, -1.2286, -0.4688,  1.5225,\n",
              "         -0.8599, -1.0303,  0.9022,  1.8892, -0.5921,  1.0696, -2.1109, -0.0218,\n",
              "         -1.9433, -0.5030, -0.4883,  0.1110, -1.3417,  0.1998,  1.2354, -0.7409,\n",
              "          1.5751,  1.5514, -0.1364,  0.3300, -1.1458, -0.2720, -2.1534, -0.8027],\n",
              "        [-0.7033, -0.2057, -0.5244,  0.6666,  0.5525, -1.4564,  0.4557, -0.2607,\n",
              "         -1.8021,  0.7689, -1.2871, -1.4578, -0.4310, -0.8388,  0.9174, -0.0400,\n",
              "          0.6272,  2.3847,  3.1297,  0.9102,  0.8623,  0.4861, -0.9336, -0.8199,\n",
              "          1.7278,  1.0172,  1.9865,  0.7298,  0.2276,  0.1687,  0.2192,  0.8979]],\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#########################\n",
        "# SINGLE HEAD ATTENTION #\n",
        "#########################"
      ],
      "metadata": {
        "id": "kVyuxDh5Rwvo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# since its not MultiHeadAttention input_dim == output_dim\n",
        "block_size = len(t) if t is not None else block_size\n",
        "\n",
        "key_layer = nn.Linear(in_features=embedding_dim, out_features=embedding_dim)\n",
        "query_layer = nn.Linear(in_features=embedding_dim, out_features=embedding_dim)\n",
        "value_layer = nn.Linear(in_features=embedding_dim, out_features=embedding_dim)\n",
        "tril = torch.tril(torch.ones(block_size, block_size, dtype=torch.long))"
      ],
      "metadata": {
        "id": "CLdJKYDZm7cP"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = key_layer(embedded_tensor)\n",
        "q = query_layer(embedded_tensor)\n",
        "wei = (q @ k.transpose(-2,-1)) / (embedding_dim ** -0.5)\n",
        "wei = wei.masked_fill(tril == 0, -float(\"inf\"))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "v = value_layer(embedded_tensor)\n",
        "\n",
        "out = wei @ v\n",
        "wei, out"
      ],
      "metadata": {
        "id": "3WSinYAipzEh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ce8fb1d-c35c-4e60-99c8-5aed69dea7e2"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "         [4.4617e-10, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "         [3.4815e-26, 9.9050e-08, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "         [4.8059e-18, 3.7613e-24, 2.9675e-08, 1.0000e+00, 0.0000e+00],\n",
              "         [9.9995e-01, 5.4872e-05, 2.8917e-22, 1.4990e-29, 6.6640e-10]],\n",
              "        grad_fn=<SoftmaxBackward0>),\n",
              " tensor([[ 0.4012,  0.1096,  1.2421, -0.1876, -0.6656,  0.4108, -0.2936, -0.5350,\n",
              "           0.0802,  0.0615,  0.0282, -0.6259,  0.9548,  0.7146, -0.3993, -0.5750,\n",
              "          -0.4476, -0.1339, -0.5695, -1.1833,  0.4406, -0.4054, -0.1534, -0.1182,\n",
              "           0.3593, -0.2678, -0.6013, -1.0542,  0.3007, -0.0448, -0.1898,  0.6341],\n",
              "         [-0.3699, -1.8706,  0.2445, -0.9308, -0.1890,  0.6169, -0.5355, -0.8250,\n",
              "           1.4217, -1.2424,  0.8778, -0.7089,  0.2601, -0.4499, -1.1164,  0.6310,\n",
              "           0.5790, -0.7322,  0.8378, -1.2645,  1.5278,  1.0927, -0.7256, -0.0085,\n",
              "           0.1970,  1.0582,  0.0166, -0.3110,  0.7048,  0.3910,  0.0312, -0.8935],\n",
              "         [ 0.3525,  0.0746, -0.1278, -0.0785, -0.9088, -0.0044, -0.3303, -0.7878,\n",
              "           1.7932, -0.0500, -1.0515,  0.7085, -0.3680, -0.6392, -0.3918,  0.5607,\n",
              "           0.1940,  0.2112,  0.0239, -0.7041,  0.6639,  0.5129,  0.0949,  0.9959,\n",
              "           0.3861, -0.1496, -0.3229, -0.6979, -0.1287,  1.0024, -0.0034, -0.2999],\n",
              "         [-0.2455,  1.5746, -0.1287, -0.6888, -0.0474,  0.9734, -0.0033,  1.1377,\n",
              "           1.1263, -1.1735,  0.4629, -0.0277,  0.0020,  0.3963, -0.3367, -1.2955,\n",
              "           1.0555,  1.1113,  0.5241, -1.3449, -0.5351,  1.0221, -1.1243,  0.4696,\n",
              "           0.4615, -0.7664, -0.5035,  0.0034,  1.3076, -0.2370,  0.2506,  0.7672],\n",
              "         [ 0.4012,  0.1095,  1.2421, -0.1877, -0.6656,  0.4108, -0.2936, -0.5351,\n",
              "           0.0802,  0.0614,  0.0283, -0.6259,  0.9547,  0.7146, -0.3993, -0.5749,\n",
              "          -0.4476, -0.1339, -0.5694, -1.1833,  0.4406, -0.4054, -0.1535, -0.1182,\n",
              "           0.3593, -0.2677, -0.6013, -1.0541,  0.3007, -0.0448, -0.1898,  0.6340]],\n",
              "        grad_fn=<MmBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########################\n",
        "# MULTI HEAD ATTENTION #\n",
        "########################"
      ],
      "metadata": {
        "id": "-JTijNAxr3l3"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionHead(nn.Module):\n",
        "\n",
        "  def __init__(self, embedding_dim, head_size):\n",
        "    super().__init__()\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.query_layer = nn.Linear(in_features=embedding_dim, out_features=head_size)\n",
        "    self.key_layer = nn.Linear(in_features=embedding_dim, out_features=head_size)\n",
        "    self.value_layer = nn.Linear(in_features=embedding_dim, out_features=head_size)\n",
        "    self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size, dtype=torch.long)))\n",
        "\n",
        "  def forward(self, x):\n",
        "    B, T, C = x.shape\n",
        "    q = self.query_layer(x)\n",
        "    k = self.key_layer(x)\n",
        "    v = self.value_layer(x)\n",
        "    wei = (q @ k.transpose(-2,-1)) / C ** -0.5\n",
        "    wei = wei.masked_fill(self.tril == 0, float(\"-inf\"))\n",
        "    wei = F.softmax(wei, dim=-1)\n",
        "    out = wei @ v\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "HM_aXT9Er7lP"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "  def __init__(self, embedding_dim, n_heads):\n",
        "    super().__init__()\n",
        "    head_size = embedding_dim // n_heads\n",
        "    self.heads = nn.ModuleList([AttentionHead(embedding_dim=embedding_dim, head_size=head_size) for _ in range(n_heads)])\n",
        "    self.projection_layer = nn.Linear(in_features=embedding_dim, out_features=embedding_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = torch.cat([head(x) for head in self.heads], dim=-1)\n",
        "    out = self.projection_layer(x)\n",
        "    return out"
      ],
      "metadata": {
        "id": "X_0YzYwJvHs9"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_tensor = embedded_tensor.unsqueeze(0)\n",
        "embedded_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igleMpjk2won",
        "outputId": "46ee6048-4658-42c0-ac44-7f7456251138"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multi_head_attention = MultiHeadAttention(embedding_dim=embedding_dim, n_heads=n_heads)\n",
        "multi_head_attention(embedded_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrrWxTzt1VkU",
        "outputId": "9697d16e-b241-4bc5-cd12-b098f68c1721"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.3960,  0.1228,  0.1425,  0.2320,  0.8935,  0.0596, -0.0883,\n",
              "          -0.2751,  0.0022, -0.0870,  0.5670, -0.2230,  0.6527, -0.2754,\n",
              "          -0.3198,  0.2378, -0.8303, -0.1637, -0.4679, -0.4889, -0.5391,\n",
              "           0.5433,  0.1891,  1.0591,  0.1788, -0.5837, -0.3828, -0.1633,\n",
              "          -0.3994, -0.1508,  0.9394,  0.7019],\n",
              "         [-0.5248, -0.1877, -0.0716, -0.5373,  0.7200, -0.4733, -0.2121,\n",
              "          -0.4697, -0.5646, -0.4163,  0.2752, -0.0155,  0.1934, -0.1055,\n",
              "           0.4372,  0.4479, -0.4577,  0.0885, -0.7893, -0.7398, -0.4251,\n",
              "           0.0441,  0.2180,  0.5846,  0.5314, -0.0373, -0.3818, -0.3136,\n",
              "           0.0224,  0.2330,  0.3222,  0.6853],\n",
              "         [-1.0075,  0.1129, -0.0110, -0.3201,  0.3604,  0.4122,  0.0969,\n",
              "          -0.6387,  0.4003, -0.4121,  0.6565, -0.6626,  0.1750, -0.6181,\n",
              "          -0.1952, -0.3119,  0.7549,  0.5559, -0.9156, -0.8544, -0.5024,\n",
              "           0.0740,  0.6636,  0.2284,  0.8663,  0.1074,  0.5612, -0.5977,\n",
              "           0.5530,  1.0429,  0.3239,  0.7685],\n",
              "         [-0.2094, -0.0342,  0.2873,  0.0743, -0.0388,  0.3776,  0.6415,\n",
              "          -0.1961,  0.2160, -0.0716,  0.1104, -0.4000,  0.4517, -0.8802,\n",
              "          -0.3587, -0.9090,  0.3616,  0.0035, -0.0927, -0.6023,  0.0957,\n",
              "           0.2734,  0.4184,  0.4638,  0.6139, -0.5329,  1.0067,  0.0400,\n",
              "           0.5570,  0.4038,  0.2323,  0.3825],\n",
              "         [-0.8668,  0.2685,  0.6198,  0.2943,  0.7423,  0.4604, -0.1584,\n",
              "           0.2582,  0.5773,  0.4404,  0.1898,  0.0987,  0.0566, -0.1653,\n",
              "          -1.0398, -0.0916,  0.2632, -0.3548,  0.3024, -0.7447, -0.5930,\n",
              "           0.2444, -0.6224,  0.4075, -0.1050, -0.5335,  1.2758, -0.3122,\n",
              "          -0.1974,  0.6050,  0.8844,  0.5286]]], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = torch.ones(4,8,3)\n",
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaYbte54hzQK",
        "outputId": "9b323af0-a803-45ae-fa8a-ca0ec9f5cdd5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(test, dim=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1TgNWpXsgvf",
        "outputId": "d3f46dca-b50c-4d73-ad46-9bb91acfce67"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3., 3., 3., 3., 3., 3., 3., 3.],\n",
              "        [3., 3., 3., 3., 3., 3., 3., 3.],\n",
              "        [3., 3., 3., 3., 3., 3., 3., 3.],\n",
              "        [3., 3., 3., 3., 3., 3., 3., 3.]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R6ziYO3ksk1k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}