{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMo4SgQk/1eTmQ4gawvnZyX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/G0nkly/pytorch_sandbox/blob/main/GPT_dimensions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "Y1aOJOJ1KCmK"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "3qCyCGVskuv4"
      },
      "outputs": [],
      "source": [
        "# Lets look at each of the layers\n",
        "# 1) Encoding\n",
        "# 2) Embedding\n",
        "# 3) Positional Encoding\n",
        "# 4) Attention: key, query, value\n",
        "# 5) Feedforward\n",
        "# 6) Block/Layernorm\n",
        "# 7) Classification / LM Head"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################\n",
        "# DATA EXAMPLE #\n",
        "################\n",
        "\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "\n",
        "with open(mode=\"r\", file=\"input.txt\") as f:\n",
        "  text = f.read()\n",
        "\n",
        "vocab = list(sorted(set(text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaC8pwxBKXVi",
        "outputId": "14059c95-0d70-483d-c1a8-5abf51dd5184"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-18 22:48:18--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt.3’\n",
            "\n",
            "\rinput.txt.3           0%[                    ]       0  --.-KB/s               \rinput.txt.3         100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-06-18 22:48:18 (17.4 MB/s) - ‘input.txt.3’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##################\n",
        "# HYPERPARAMTERS #\n",
        "##################"
      ],
      "metadata": {
        "id": "QITuTbF7KLJB"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 32\n",
        "block_size = 8\n",
        "n_heads = 4"
      ],
      "metadata": {
        "id": "inC3GWsPKQSl"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############\n",
        "# ENCODING #\n",
        "############"
      ],
      "metadata": {
        "id": "KznIrUvIJrAn"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {v:k for k,v in enumerate(vocab)}\n",
        "itos = {k:v for k,v in enumerate(vocab)}\n",
        "encode = lambda seq: [stoi[char] for char in seq]\n",
        "decode = lambda numbers: \"\".join([itos[num] for num in numbers])\n",
        "\n",
        "def get_batch(split: str):\n",
        "  dataset = train if split == \"train\" else val"
      ],
      "metadata": {
        "id": "ghD7YPk8HXsr"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#############\n",
        "# EMBEDDING #\n",
        "#############"
      ],
      "metadata": {
        "id": "7bf0P7L9Id9u"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)"
      ],
      "metadata": {
        "id": "d0zeDIuzKBgA"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor(encode(\"Haubi\"))"
      ],
      "metadata": {
        "id": "HirEowEUODk6"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyIOe9_tOMPE",
        "outputId": "be0f7eaa-0978-4e72-f61d-97d1e2574f10"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.9655,  2.1420,  0.1026, -0.1567,  0.2709, -0.0079,  0.5604, -1.3238,\n",
              "          0.6949, -0.6346, -0.4504,  0.3740,  0.3065,  0.6298,  0.2285,  0.3683,\n",
              "          0.2725, -0.6920,  0.1760,  0.1325, -0.0071,  0.9312, -1.2538,  0.7064,\n",
              "          0.7876, -0.0338, -0.1693,  1.4249, -0.5741, -1.2141, -0.7215, -1.2245],\n",
              "        [ 0.3530, -1.6809,  1.4108,  1.1818,  1.0998, -0.9324, -0.8904, -0.4201,\n",
              "         -1.1354,  1.4010, -1.3822,  0.9621,  1.0063, -1.5000, -0.4825, -0.3301,\n",
              "          0.5177, -1.4639,  1.0956,  1.1664,  1.4591,  2.3299, -1.0775,  0.1901,\n",
              "          0.4501,  0.3235, -0.3753,  0.0261,  0.7775, -0.3224, -0.2147,  0.0438],\n",
              "        [ 1.2298,  0.4247,  0.4889, -0.6393, -2.7005, -0.2637, -0.8545, -0.5603,\n",
              "         -0.0794,  0.6169,  0.2654, -0.0371,  0.4269,  0.9110, -0.1900,  0.2717,\n",
              "         -0.2002,  0.7572, -0.0031,  2.3400,  0.1033, -0.1757, -1.5082, -0.6113,\n",
              "          0.1707, -0.9771,  0.4434,  0.1899, -0.7733,  0.9318, -1.2209,  0.2367],\n",
              "        [ 0.0068,  0.7628, -0.1668, -1.7789,  0.6346,  1.1668, -0.1154, -0.0095,\n",
              "         -0.1290,  2.4047,  0.2953, -0.5793, -0.7662,  1.4763, -1.7419, -0.5885,\n",
              "          1.0793,  0.5263,  0.9098,  0.0416,  0.0498, -0.4530, -1.0300,  0.9843,\n",
              "          0.0286, -1.2549,  1.1158,  0.5598,  0.9091,  2.5709,  0.9766, -0.1473],\n",
              "        [ 0.5427,  0.1755, -0.1739, -0.8517,  0.8271, -0.7370,  1.7995,  0.0042,\n",
              "          1.9272, -1.5700, -1.9196,  0.7504,  1.4225, -0.9421,  0.6519,  1.9829,\n",
              "         -0.5603, -0.7077, -0.5387,  1.7425, -0.8067, -0.5916,  0.5509,  0.9313,\n",
              "          2.2727, -0.6412, -1.2517, -0.7577, -1.2189,  0.5698, -1.5637,  0.4645]],\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#########################\n",
        "# POSITIONAL 'ENCODING' #\n",
        "#########################"
      ],
      "metadata": {
        "id": "uEBhtYKQONlj"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "postional_embedding = nn.Embedding(num_embeddings=5, embedding_dim=32)"
      ],
      "metadata": {
        "id": "dHmnOaSVPmeS"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "postional_embedding(torch.arange(5)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24mQLBiyReS5",
        "outputId": "f256899f-8572-43bf-9efb-365b599fcd6b"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_tensor = embedding(t) + postional_embedding(torch.arange(5, dtype=torch.long))\n",
        "embedded_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnBn3VO3RnEw",
        "outputId": "3da90ecc-bad3-44a9-982c-f997bf5b3d2f"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0962,  1.1098, -0.1119, -0.8120, -0.8776, -1.4015,  1.3507, -0.2814,\n",
              "          1.4955, -0.1668, -1.4774,  0.2952, -0.3414, -0.3457,  1.9336,  0.8511,\n",
              "          0.7062, -0.9392,  0.4825,  0.9020,  2.0514, -0.0618,  0.4034,  1.4067,\n",
              "          0.6454, -1.2013,  0.8931,  1.6418, -0.5308, -0.2597, -0.2019, -2.2324],\n",
              "        [ 2.1937, -2.6700,  0.7154,  1.7961,  0.5056, -0.6785, -0.5441, -0.4413,\n",
              "          0.2473,  1.4805, -1.9954, -0.9950,  0.6226,  0.4948, -0.9403, -1.8405,\n",
              "         -1.6159, -1.7384,  0.8802,  1.6368,  1.9047,  1.4315, -0.1333,  1.2675,\n",
              "         -1.6029, -0.6302, -1.3378, -0.3097, -0.7311, -0.2391,  0.4505,  1.4686],\n",
              "        [ 1.9625, -0.0598,  0.5681, -1.0882, -3.1110,  0.7178, -1.7550, -2.1459,\n",
              "          0.2455, -1.6774,  0.1030, -0.1173,  0.0333,  1.5377,  0.8426,  1.1725,\n",
              "          0.9124, -0.6408,  0.9636,  2.1868,  0.4553,  1.2068, -1.7151,  0.1319,\n",
              "          1.7400, -1.0255, -0.2647,  1.5574, -1.7029,  1.1208,  0.1079, -1.2516],\n",
              "        [-1.8695,  1.2554, -1.5623, -1.4960,  1.3753,  1.5616, -0.4709,  0.3059,\n",
              "          0.9121,  0.7240, -0.0062,  0.0419,  0.0608, -0.4600, -1.9433,  0.9118,\n",
              "          1.8305,  0.1052, -0.2929, -1.0572,  0.1756, -0.9954, -2.9888,  1.0167,\n",
              "          0.3135,  0.0115,  2.4691,  0.2477,  3.0892,  2.1536, -0.9538,  0.6478],\n",
              "        [ 1.4840,  1.1736, -1.3447,  0.3995,  0.3479, -1.4671,  2.4810,  0.7683,\n",
              "          2.8464, -0.8322, -1.0758, -0.0753,  2.3736, -0.6358,  0.0914,  1.5501,\n",
              "         -1.3250, -0.8838, -1.2254,  3.2605, -2.1899, -1.1424, -0.3301,  1.1393,\n",
              "          2.8403, -0.1535, -0.9179, -2.4152,  0.0437,  0.4659, -2.4157,  0.2813]],\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#########################\n",
        "# SINGLE HEAD ATTENTION #\n",
        "#########################"
      ],
      "metadata": {
        "id": "kVyuxDh5Rwvo"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# since its not MultiHeadAttention input_dim == output_dim\n",
        "block_size = len(t) if t is not None else block_size\n",
        "\n",
        "key_layer = nn.Linear(in_features=embedding_dim, out_features=embedding_dim)\n",
        "query_layer = nn.Linear(in_features=embedding_dim, out_features=embedding_dim)\n",
        "value_layer = nn.Linear(in_features=embedding_dim, out_features=embedding_dim)\n",
        "tril = torch.tril(torch.ones(block_size, block_size, dtype=torch.long))"
      ],
      "metadata": {
        "id": "CLdJKYDZm7cP"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = key_layer(embedded_tensor)\n",
        "q = query_layer(embedded_tensor)\n",
        "wei = (q @ k.transpose(-2,-1)) / (embedding_dim ** -0.5)\n",
        "wei = wei.masked_fill(tril == 0, -float(\"inf\"))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "v = value_layer(embedded_tensor)\n",
        "\n",
        "out = wei @ v\n",
        "wei, out"
      ],
      "metadata": {
        "id": "3WSinYAipzEh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e688f897-2646-4cac-b4e4-254449b20f14"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "         [1.0000e+00, 1.2141e-11, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "         [2.0567e-05, 9.9998e-01, 4.6030e-07, 0.0000e+00, 0.0000e+00],\n",
              "         [1.6771e-14, 1.0000e+00, 6.4606e-17, 9.8931e-20, 0.0000e+00],\n",
              "         [3.6904e-13, 1.8030e-06, 1.3597e-26, 6.5784e-08, 1.0000e+00]],\n",
              "        grad_fn=<SoftmaxBackward0>),\n",
              " tensor([[-1.0764,  0.5365,  0.1440,  0.5200, -0.3727, -0.3480, -0.6684, -1.0946,\n",
              "           0.1395,  0.3309, -0.4356,  0.4809, -0.5565,  0.3512,  0.1686,  0.4983,\n",
              "           0.6177,  0.5295, -0.7163,  0.1302, -0.9579, -0.2277, -0.5855, -0.4906,\n",
              "          -0.8270, -0.1705, -1.7216,  0.3792, -0.0156, -0.1709, -0.0939, -0.1256],\n",
              "         [-1.0764,  0.5365,  0.1440,  0.5200, -0.3727, -0.3480, -0.6684, -1.0946,\n",
              "           0.1395,  0.3309, -0.4356,  0.4809, -0.5565,  0.3512,  0.1686,  0.4983,\n",
              "           0.6177,  0.5295, -0.7163,  0.1302, -0.9579, -0.2277, -0.5855, -0.4906,\n",
              "          -0.8270, -0.1705, -1.7216,  0.3792, -0.0156, -0.1709, -0.0939, -0.1256],\n",
              "         [ 0.1893, -0.2881, -0.1711, -0.2231,  0.5517, -0.9077, -0.3428,  0.4646,\n",
              "           0.1738,  0.6339,  0.3336, -1.6100,  0.8780, -1.8835, -0.6426,  0.2846,\n",
              "           0.4023,  0.6637, -0.1128,  1.4646, -0.6197, -1.2185, -0.1624,  1.6688,\n",
              "           1.1828, -0.2404, -0.0704, -0.2665,  0.9579,  0.5971, -0.5490, -0.6856],\n",
              "         [ 0.1893, -0.2881, -0.1711, -0.2231,  0.5518, -0.9077, -0.3428,  0.4646,\n",
              "           0.1738,  0.6339,  0.3337, -1.6100,  0.8781, -1.8835, -0.6426,  0.2846,\n",
              "           0.4022,  0.6637, -0.1128,  1.4646, -0.6197, -1.2185, -0.1624,  1.6688,\n",
              "           1.1828, -0.2404, -0.0704, -0.2665,  0.9579,  0.5972, -0.5490, -0.6856],\n",
              "         [-1.4375, -0.0851,  0.7228,  1.1774, -0.4078, -1.3020,  0.1920,  0.6108,\n",
              "           0.0636, -0.1073,  0.2687, -0.4268, -1.4094,  0.4068,  0.3160, -0.0436,\n",
              "          -0.0757,  1.1157,  0.6119,  0.3071, -1.2098,  0.9750, -0.9662, -0.3871,\n",
              "          -0.7209, -1.2137,  0.4584,  0.9513,  0.4676,  2.0127,  1.9918,  0.1682]],\n",
              "        grad_fn=<MmBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########################\n",
        "# MULTI HEAD ATTENTION #\n",
        "########################"
      ],
      "metadata": {
        "id": "-JTijNAxr3l3"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionHead(nn.Module):\n",
        "\n",
        "  def __init__(self, embedding_dim, head_size):\n",
        "    super().__init__()\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.query_layer = nn.Linear(in_features=embedding_dim, out_features=head_size)\n",
        "    self.key_layer = nn.Linear(in_features=embedding_dim, out_features=head_size)\n",
        "    self.value_layer = nn.Linear(in_features=embedding_dim, out_features=head_size)\n",
        "    self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size, dtype=torch.long)))\n",
        "\n",
        "  def forward(self, x):\n",
        "    B, T, C = x.shape\n",
        "    q = self.query_layer(x)\n",
        "    k = self.key_layer(x)\n",
        "    v = self.value_layer(x)\n",
        "    wei = (q @ k.transpose(-2,-1)) / C ** -0.5\n",
        "    wei = wei.masked_fill(self.tril == 0, float(\"-inf\"))\n",
        "    wei = F.softmax(wei, dim=-1)\n",
        "    out = wei @ v\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "HM_aXT9Er7lP"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "  def __init__(self, embedding_dim, n_heads):\n",
        "    super().__init__()\n",
        "    head_size = embedding_dim // n_heads\n",
        "    self.heads = nn.ModuleList([AttentionHead(embedding_dim=embedding_dim, head_size=head_size) for _ in range(n_heads)])\n",
        "    self.projection_layer = nn.Linear(in_features=embedding_dim, out_features=embedding_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = torch.cat([head(x) for head in self.heads], dim=-1)\n",
        "    out = self.projection_layer(x)\n",
        "    return out"
      ],
      "metadata": {
        "id": "X_0YzYwJvHs9"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_tensor = embedded_tensor.unsqueeze(0)\n",
        "embedded_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igleMpjk2won",
        "outputId": "e3b7319a-af09-4511-817e-29fd8c26a022"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multi_head_attention = MultiHeadAttention(embedding_dim=embedding_dim, n_heads=n_heads)\n",
        "t_ma = multi_head_attention(embedded_tensor)\n",
        "t_ma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrrWxTzt1VkU",
        "outputId": "7ce45eb9-642c-4867-9f37-8b95515111f1"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 3.1181e-01,  1.2491e-01, -1.5138e-01,  4.1956e-01, -5.3279e-01,\n",
              "           1.7668e-01, -7.4490e-02, -6.5640e-02,  4.7382e-02, -1.0647e+00,\n",
              "           3.6990e-01, -4.2196e-01,  8.8334e-02,  3.0116e-01, -4.6426e-02,\n",
              "          -3.9286e-02,  4.6723e-02,  2.9490e-01, -2.1028e-01, -2.8957e-01,\n",
              "          -8.2012e-02,  4.2746e-01, -4.5696e-01,  2.1170e-01,  1.4161e-03,\n",
              "           2.0678e-01,  4.9818e-02,  5.9980e-01,  1.3458e-01,  4.1500e-01,\n",
              "          -6.1290e-01, -3.8942e-02],\n",
              "         [ 1.0971e-01,  1.6192e-02, -1.7401e-01,  3.2227e-01, -3.1322e-01,\n",
              "           6.0930e-01, -1.6385e-01, -1.5799e-01,  1.7411e-01, -7.8808e-01,\n",
              "           5.8384e-01, -4.1368e-01, -1.1081e-01,  4.9320e-01,  1.5624e-01,\n",
              "           1.4238e-01, -4.6980e-02,  2.7358e-01,  1.0587e-01, -4.0231e-01,\n",
              "          -1.5190e-01,  2.2247e-01, -3.7877e-01,  2.3561e-01,  4.1086e-02,\n",
              "           1.5494e-01,  8.9608e-02,  4.6367e-01,  1.3130e-01,  3.4374e-01,\n",
              "          -4.2633e-01, -3.9975e-02],\n",
              "         [ 8.2690e-02,  5.3106e-01, -4.4844e-01,  5.2919e-01, -9.1862e-01,\n",
              "          -4.8633e-02, -7.9048e-01,  7.0401e-01,  7.1015e-01, -1.2229e+00,\n",
              "           5.6033e-01,  3.7362e-01,  3.9765e-01,  4.0644e-02, -2.6162e-01,\n",
              "          -1.9037e-01, -3.4877e-02, -2.0558e-01,  1.3134e-01,  4.6019e-02,\n",
              "          -5.3496e-01,  5.0682e-01,  1.9226e-01,  6.2583e-01,  2.4540e-01,\n",
              "           3.0227e-01, -6.0347e-01,  5.9357e-01, -2.0902e-01,  2.0277e-01,\n",
              "          -5.5211e-01, -3.6504e-01],\n",
              "         [-2.5747e-03,  1.4507e-01, -1.0131e-01,  3.5143e-02, -5.9692e-01,\n",
              "           3.9571e-01,  5.4200e-01,  4.6963e-03, -1.4245e-02, -3.1435e-01,\n",
              "           1.7209e-01, -3.6763e-01, -1.3189e-01, -2.3432e-01, -4.1860e-01,\n",
              "          -5.9561e-01,  1.4109e-01,  6.6107e-01, -1.0602e-01, -4.0581e-01,\n",
              "           4.3967e-02,  1.3446e-01, -2.4260e-01,  5.2107e-01, -2.1806e-01,\n",
              "          -1.4020e-01, -3.5468e-01,  2.5822e-02, -3.2544e-02,  3.7126e-01,\n",
              "           1.4328e-01,  3.1765e-02],\n",
              "         [ 1.4032e-01, -6.7260e-02, -2.9633e-01,  1.4740e-01,  4.4529e-01,\n",
              "           9.2220e-02,  3.6617e-02,  4.3819e-03, -8.3582e-01, -2.3687e-01,\n",
              "           2.8572e-01,  2.3216e-01, -2.9264e-01,  7.6942e-01,  2.1779e-01,\n",
              "           6.3202e-01, -6.6807e-01,  5.2487e-01, -1.4276e+00, -2.8128e-01,\n",
              "          -2.6852e-01, -5.2067e-01, -5.9142e-01, -8.6244e-02,  6.3898e-01,\n",
              "          -7.8573e-01,  1.0579e+00,  6.9065e-02, -2.0632e-01,  2.3170e-01,\n",
              "          -1.2800e-02,  8.8994e-02]]], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################\n",
        "# FEED-FORWARD #\n",
        "################"
      ],
      "metadata": {
        "id": "t7QOv8O_Cian"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feed_forward_layer = nn.Sequential(\n",
        "    nn.Linear(32, 4 * 32),\n",
        "    nn.Linear(4 * 32, 32)\n",
        ")\n",
        "\n",
        "t_ff = feed_forward_layer(t_ma)\n",
        "t_ff"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oJhELEiCgs0",
        "outputId": "419446c8-957f-40de-8f28-84939a4328ba"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1855,  0.1406, -0.0098,  0.1068, -0.0608,  0.1157,  0.0850,\n",
              "          -0.1138, -0.1459, -0.0182,  0.1400,  0.1149,  0.2611, -0.0882,\n",
              "          -0.2060,  0.1214, -0.2081,  0.1017, -0.1771, -0.0876,  0.2088,\n",
              "          -0.0775, -0.1045, -0.0029,  0.1517, -0.0692, -0.0889, -0.1469,\n",
              "          -0.2707, -0.0705,  0.1229,  0.0825],\n",
              "         [ 0.1039,  0.1608,  0.1023,  0.0901, -0.0978,  0.1811, -0.0161,\n",
              "          -0.0798, -0.0830,  0.0105,  0.1548,  0.0488,  0.2979, -0.1161,\n",
              "          -0.1387,  0.1327, -0.2271,  0.1563, -0.1706, -0.0578,  0.1238,\n",
              "          -0.0939, -0.0981, -0.0268,  0.1190, -0.0958,  0.0378, -0.1055,\n",
              "          -0.2925, -0.0595,  0.1302,  0.1399],\n",
              "         [ 0.0218,  0.1157, -0.0471,  0.2463, -0.1132, -0.1050,  0.3254,\n",
              "          -0.1132, -0.0178, -0.2035,  0.1378,  0.0899,  0.3808,  0.1055,\n",
              "          -0.0078, -0.0925, -0.2688,  0.1456, -0.2976, -0.2060,  0.4078,\n",
              "           0.0199, -0.4583,  0.0058,  0.2251,  0.0942, -0.1280, -0.2469,\n",
              "          -0.1817, -0.1317,  0.1759,  0.1547],\n",
              "         [ 0.0873,  0.1462, -0.0163,  0.0502,  0.0441,  0.1190, -0.0691,\n",
              "          -0.1662, -0.1637, -0.2739, -0.0622,  0.0072,  0.3395,  0.0183,\n",
              "          -0.0723,  0.0697,  0.0016,  0.0459,  0.0347,  0.0094,  0.1703,\n",
              "          -0.1052, -0.0281, -0.1039,  0.2216,  0.0178, -0.0192, -0.0033,\n",
              "          -0.1689,  0.0718,  0.0040,  0.0150],\n",
              "         [-0.1728, -0.1153,  0.3081,  0.0084, -0.0106, -0.0138,  0.2867,\n",
              "           0.0108, -0.4084,  0.1845,  0.0083, -0.1533,  0.0390, -0.2023,\n",
              "          -0.3558,  0.5639,  0.0707,  0.2821, -0.0681,  0.1487,  0.1350,\n",
              "          -0.0387,  0.3632,  0.0584, -0.0232, -0.1095,  0.2486,  0.0437,\n",
              "          -0.3887, -0.1421,  0.0258, -0.2090]]], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########################\n",
        "# BLOCK AND LAYER-NORM #\n",
        "########################"
      ],
      "metadata": {
        "id": "oazuvtJZyeEq"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionBlock(nn.Module):\n",
        "\n",
        "  def __init__(self, embedding_dim, n_heads):\n",
        "    super().__init__()\n",
        "    self.multi_head_attention = MultiHeadAttention(embedding_dim=embedding_dim, n_heads=n_heads)\n",
        "    self.feed_forward = nn.Sequential(\n",
        "        nn.Linear(in_features=embedding_dim, out_features=4 * embedding_dim),\n",
        "        nn.Linear(4 * embedding_dim, embedding_dim)\n",
        "    )\n",
        "    self.ln_1 = nn.LayerNorm(embedding_dim)\n",
        "    self.ln_2 = nn.LayerNorm(embedding_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x + self.multi_head_attention(self.ln_1(x))\n",
        "    x = x + self.feed_forward(self.ln_2(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "1yZ90h90BcKM"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_block = AttentionBlock(embedding_dim=embedding_dim, n_heads=n_heads)\n",
        "t_block_2 = attention_block(t_ff)\n",
        "t_block_2"
      ],
      "metadata": {
        "id": "F0lyArs6Nw2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1fc3ce9-f47d-4ddf-f70c-94b4f238d09e"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.3593,  0.4308, -0.0341, -0.0758, -0.6614,  0.4628,  0.6237,\n",
              "          -0.6133, -0.8757,  0.5346,  0.0156,  0.2852,  0.2849,  0.0760,\n",
              "          -0.6488,  0.4055, -0.3469, -0.0933, -0.2119, -0.2616,  0.0562,\n",
              "           0.4644, -0.1922,  0.9401,  0.7545, -0.6049, -0.7730, -0.0098,\n",
              "           0.2786,  0.2299, -0.2957,  0.8753],\n",
              "         [-0.4488,  0.4442,  0.1905, -0.6152, -0.3231,  0.5525,  0.5207,\n",
              "          -0.4730, -0.8173,  0.5421, -0.0208,  0.3799,  0.2891, -0.0610,\n",
              "          -0.4813,  0.3213, -0.2833,  0.1647, -0.2629, -0.4480,  0.0668,\n",
              "           0.2828, -0.2775,  0.5457,  0.5247, -0.5027, -0.5147, -0.0790,\n",
              "           0.3471,  0.3628, -0.3878,  0.9191],\n",
              "         [-0.7207,  0.4525, -0.2702,  0.2677, -0.2619,  0.2868,  0.9852,\n",
              "          -0.0617, -1.0268,  0.4289, -0.0144,  0.4526,  0.4052,  0.3802,\n",
              "           0.0147,  0.4973, -0.0544,  0.3741,  0.0168, -0.4563,  0.0778,\n",
              "           0.2597, -0.9783,  0.5024,  0.8982,  0.0421, -0.8502,  0.2195,\n",
              "           0.3973,  0.1194, -0.5918,  0.7668],\n",
              "         [-0.7903,  0.1532, -0.0114,  0.0427, -0.6067, -0.1179,  0.6129,\n",
              "          -1.1006, -0.1716,  0.5907, -0.2903,  0.1826,  0.9223,  0.0544,\n",
              "          -0.4562,  0.4355, -0.3875, -0.3314, -0.3783, -0.1648,  0.1677,\n",
              "           0.3233,  0.4053,  0.8588,  0.8260, -0.5127, -0.5333, -0.1096,\n",
              "           0.4495,  0.1534, -0.0039,  0.3959],\n",
              "         [-0.6777, -0.1229,  0.2871, -0.2880, -0.7268,  0.2521,  1.0150,\n",
              "          -0.4697, -1.0091,  0.7326, -0.4571,  0.2313, -0.2089,  0.0548,\n",
              "          -0.3964,  0.9260,  0.2319, -0.1614, -0.3656,  0.1205, -0.0361,\n",
              "           0.5207,  0.6591,  0.9848,  0.5975, -1.0106, -0.4030,  0.2464,\n",
              "          -0.3099, -0.2883, -0.4606,  0.5693]]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#############\n",
        "# (LM) HEAD #\n",
        "#############"
      ],
      "metadata": {
        "id": "y7sfUzouQVjD"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm_head = nn.Linear(in_features=embedding_dim, out_features=vocab_size)\n",
        "logits = lm_head(t_block_2)\n",
        "logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_U-pPfXQkDl",
        "outputId": "3c025b60-a39a-41af-9715-29335ebc35d6"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.0692, -0.0310, -0.0866, -0.2803, -0.4678, -0.5694,  0.1613,\n",
              "          -0.1169,  0.1581, -0.3940,  0.0285,  0.5748,  0.3131, -0.6899,\n",
              "           0.0111,  0.2994,  0.0951, -0.4830, -0.0173, -0.3108, -0.2294,\n",
              "          -0.1531,  0.0642, -0.0333, -0.0726, -0.6515,  0.3778, -0.0038,\n",
              "          -0.2874,  0.5143,  0.1092, -0.0300,  0.0368,  0.6291, -0.1461,\n",
              "          -0.2808,  0.1075,  0.2912, -0.5865,  0.1630,  0.0140, -0.0544,\n",
              "          -0.4655, -0.3081, -0.1966, -0.0066,  0.0783, -0.4945, -0.1965,\n",
              "          -0.4655,  0.1096, -0.5573, -0.0839,  0.3681,  0.2428, -0.1737,\n",
              "           0.0528, -0.4109, -0.1231, -0.3206, -0.1888,  0.0827,  0.0030,\n",
              "           0.2019, -0.1586],\n",
              "         [ 0.0247, -0.0553, -0.1140, -0.2454, -0.3870, -0.5276,  0.0851,\n",
              "          -0.0589,  0.2005, -0.3367,  0.0100,  0.7434,  0.3223, -0.5889,\n",
              "          -0.0238,  0.3554,  0.1088, -0.3334, -0.0434, -0.3590, -0.2698,\n",
              "          -0.2529, -0.0556,  0.1088, -0.1715, -0.5449,  0.2591,  0.1274,\n",
              "          -0.1987,  0.4585,  0.0577, -0.0926,  0.0039,  0.4397,  0.0183,\n",
              "          -0.2278,  0.2004,  0.1551, -0.5891,  0.2022, -0.0805,  0.0482,\n",
              "          -0.4584, -0.3436, -0.2753, -0.0791, -0.0544, -0.4802, -0.1104,\n",
              "          -0.3092,  0.2506, -0.4595,  0.0646,  0.2719,  0.1629, -0.2213,\n",
              "           0.0744, -0.4490, -0.1200, -0.3156, -0.3334,  0.1802,  0.0979,\n",
              "           0.1064, -0.0250],\n",
              "         [-0.0341,  0.1791, -0.4496, -0.2070,  0.0316, -0.6544,  0.0872,\n",
              "          -0.1070,  0.1538, -0.4151,  0.1014,  0.6482,  0.4264, -0.2803,\n",
              "           0.0138,  0.1739, -0.0485, -0.3893, -0.0718, -0.5169, -0.4262,\n",
              "           0.0854, -0.2042,  0.3075, -0.3874, -0.4931, -0.0120, -0.0348,\n",
              "           0.0314,  0.6767, -0.0972, -0.3184,  0.0234,  0.5792, -0.0666,\n",
              "          -0.4102,  0.1401,  0.3216, -0.6611,  0.1590,  0.2442,  0.1132,\n",
              "          -0.3210, -0.4671, -0.0233,  0.2001,  0.1812, -0.3436,  0.1270,\n",
              "          -0.7912,  0.3359, -0.3710,  0.5538,  0.4101,  0.3893, -0.1443,\n",
              "           0.1131, -0.4476, -0.1367, -0.0728, -0.1258,  0.3819,  0.2785,\n",
              "           0.2956,  0.0394],\n",
              "         [ 0.1836, -0.3818, -0.1483, -0.2943, -0.4066, -0.3749,  0.0187,\n",
              "           0.0468, -0.0084, -0.1755,  0.0784,  0.5818,  0.1728, -0.6459,\n",
              "          -0.0146, -0.1092,  0.0665, -0.6803, -0.1727, -0.1107,  0.1387,\n",
              "          -0.2147,  0.2669, -0.0661, -0.1383, -0.3205,  0.5781, -0.1195,\n",
              "          -0.4765,  0.0711,  0.2816, -0.0267,  0.0257,  0.4162, -0.2859,\n",
              "          -0.0762, -0.0562,  0.1726, -0.3513, -0.2031, -0.3670, -0.2034,\n",
              "          -0.2867, -0.3988, -0.1738, -0.2626,  0.0700, -0.3758, -0.3397,\n",
              "          -0.3890,  0.0782, -0.4455, -0.1492,  0.0663, -0.0121,  0.0369,\n",
              "           0.2603,  0.0259,  0.2161, -0.3475, -0.0273, -0.3608,  0.0230,\n",
              "           0.2644, -0.0851],\n",
              "         [-0.0875, -0.3377,  0.0177, -0.3304, -0.5392, -0.8154,  0.2268,\n",
              "          -0.0749,  0.2980, -0.6721,  0.0124,  0.4625, -0.0546, -0.6718,\n",
              "           0.4431,  0.1364,  0.1543, -0.4521, -0.0255, -0.4864, -0.3125,\n",
              "          -0.0963,  0.6083,  0.0578,  0.3925, -0.6184,  0.4162,  0.0168,\n",
              "          -0.0367,  0.1872, -0.0335,  0.1270,  0.0998,  0.1455, -0.2360,\n",
              "          -0.0794,  0.3096,  0.3194, -0.3301,  0.3813, -0.0847,  0.0603,\n",
              "          -0.3947, -0.1594, -0.0676, -0.3573,  0.0338, -0.6535, -0.3082,\n",
              "          -0.4563, -0.3277, -0.6873, -0.0134,  0.2453,  0.2892, -0.1176,\n",
              "           0.1049, -0.3179,  0.1726, -0.1542, -0.1791,  0.0023,  0.0750,\n",
              "           0.1860,  0.0342]]], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###########\n",
        "# Softmax #\n",
        "###########"
      ],
      "metadata": {
        "id": "thcq_pd9Uer-"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = F.softmax(logits[:, -1, :], dim=-1)\n",
        "encoded_token = torch.argmax(probs)\n",
        "probs, encoded_token\n",
        "decode([encoded_token.item()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sy3HSPqwUhff",
        "outputId": "5dff9f2c-ad4a-42cd-a509-38a9bd431052"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'J'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = torch.ones(4,8,3)\n",
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaYbte54hzQK",
        "outputId": "67d0ab7f-e4d8-4d75-f075-a26da89d15f5"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(test, dim=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1TgNWpXsgvf",
        "outputId": "98bfdd08-a99c-442c-afa2-0fca57b9ab1e"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3., 3., 3., 3., 3., 3., 3., 3.],\n",
              "        [3., 3., 3., 3., 3., 3., 3., 3.],\n",
              "        [3., 3., 3., 3., 3., 3., 3., 3.],\n",
              "        [3., 3., 3., 3., 3., 3., 3., 3.]])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R6ziYO3ksk1k"
      },
      "execution_count": 33,
      "outputs": []
    }
  ]
}