{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcce8V8CoCqi6fspxQhBt/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/G0nkly/pytorch_sandbox/blob/main/GPT_dimensions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "Y1aOJOJ1KCmK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3qCyCGVskuv4"
      },
      "outputs": [],
      "source": [
        "# Lets look at each of the layers\n",
        "# 1) Encoding\n",
        "# 2) Embedding\n",
        "# 3) Positional Encoding\n",
        "# 4) Attention: key, query, value\n",
        "# 5) Feedforward\n",
        "# 6) Block/Layernorm\n",
        "# 7) Classification / LM Head"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################\n",
        "# DATA EXAMPLE #\n",
        "################\n",
        "\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "\n",
        "with open(mode=\"r\", file=\"input.txt\") as f:\n",
        "  text = f.read()\n",
        "\n",
        "vocab = list(sorted(set(text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaC8pwxBKXVi",
        "outputId": "681aa910-ce04-4ea7-aeb5-ed90f043af21"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-16 19:27:51--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2025-06-16 19:27:51 (13.4 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##################\n",
        "# HYPERPARAMTERS #\n",
        "##################"
      ],
      "metadata": {
        "id": "QITuTbF7KLJB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 32\n",
        "block_size = 8\n",
        "n_heads = 4"
      ],
      "metadata": {
        "id": "inC3GWsPKQSl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############\n",
        "# ENCODING #\n",
        "############"
      ],
      "metadata": {
        "id": "KznIrUvIJrAn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {v:k for k,v in enumerate(vocab)}\n",
        "itos = {k:v for k,v in enumerate(vocab)}\n",
        "encode = lambda seq: [stoi[char] for char in seq]\n",
        "decode = lambda numbers: \"\".join([itos[num] for num in numbers])\n",
        "\n",
        "def get_batch(split: str):\n",
        "  dataset = train if split == \"train\" else val"
      ],
      "metadata": {
        "id": "ghD7YPk8HXsr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#############\n",
        "# EMBEDDING #\n",
        "#############"
      ],
      "metadata": {
        "id": "7bf0P7L9Id9u"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)"
      ],
      "metadata": {
        "id": "d0zeDIuzKBgA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor(encode(\"Haubi\"))"
      ],
      "metadata": {
        "id": "HirEowEUODk6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyIOe9_tOMPE",
        "outputId": "4743b66c-45c4-4f27-9bb1-93b16bc18394"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-9.5173e-01,  5.1780e-01, -7.9678e-01, -1.3175e+00, -1.0763e+00,\n",
              "         -7.7784e-01,  2.5596e-01, -1.2730e+00,  6.0056e-01, -1.1393e-01,\n",
              "          3.6116e-01, -7.1648e-01, -2.7236e-01, -1.5923e+00, -1.9456e-02,\n",
              "         -6.7467e-01, -6.1299e-01,  1.2723e+00, -2.0015e-01, -7.8960e-01,\n",
              "         -5.7475e-02, -8.3011e-01,  1.2651e-01, -2.8292e-01, -5.4609e-01,\n",
              "          1.9741e-01, -4.4609e-02,  2.0074e+00, -1.3648e-02,  1.1672e+00,\n",
              "          1.1550e+00, -3.4768e-01],\n",
              "        [-1.5869e+00, -7.4273e-01, -2.0695e+00,  5.9974e-01, -1.6373e+00,\n",
              "          2.2822e+00,  6.8794e-01, -5.4350e-01, -3.4103e-01, -5.8377e-01,\n",
              "         -7.4508e-01,  4.3472e-01, -1.5385e+00,  1.0176e+00, -9.0352e-03,\n",
              "         -5.5720e-01,  1.0464e-01,  5.8074e-01, -1.1895e+00,  2.0971e-01,\n",
              "          1.0315e+00,  1.7061e-01, -9.8962e-01, -5.5562e-01, -9.4058e-01,\n",
              "         -1.9713e-01, -7.2097e-02, -2.0620e-01, -9.0988e-01, -1.6105e+00,\n",
              "          3.3987e-01, -1.0508e+00],\n",
              "        [-1.5462e+00,  3.6795e-01,  1.5850e-01,  6.1884e-01,  8.6636e-01,\n",
              "         -1.3202e+00, -3.6266e-01, -1.4514e-01, -3.4049e-01,  9.2281e-01,\n",
              "         -1.8721e-01,  6.9223e-01,  2.9443e-01,  3.2889e-01, -2.8282e-01,\n",
              "         -9.4435e-02,  1.7869e+00,  1.2664e+00, -1.0569e+00,  1.5573e+00,\n",
              "          1.0127e+00,  5.8352e-01, -2.1746e+00, -1.0246e+00,  1.0408e-01,\n",
              "         -3.0758e+00,  1.4007e+00, -1.7911e-01, -9.6383e-01,  2.9906e-01,\n",
              "          4.0738e-01,  1.4833e+00],\n",
              "        [-8.9170e-01, -9.3444e-01,  1.8375e+00, -3.6335e-01,  4.9215e-01,\n",
              "          2.7430e-03, -1.6548e+00, -2.4153e-01, -1.1872e-01, -2.5660e-01,\n",
              "         -2.1912e-01,  1.3092e+00, -2.5916e-01,  9.1669e-01, -9.3092e-01,\n",
              "         -2.6614e-01,  4.7069e-01, -8.6830e-01, -4.8267e-01,  4.6682e-01,\n",
              "          5.6598e-01, -1.7083e+00,  6.5556e-01, -1.3859e-01, -9.2941e-01,\n",
              "          1.5959e+00, -6.6649e-01, -3.1466e-01, -6.4294e-01, -1.5224e+00,\n",
              "          1.6648e+00,  4.2981e-01],\n",
              "        [ 1.2308e+00, -9.9830e-01,  1.1142e+00,  2.9128e+00, -3.3158e-01,\n",
              "         -1.6861e+00,  3.6552e-01,  1.8284e+00, -8.7521e-01, -2.5542e+00,\n",
              "         -8.6342e-01,  3.8226e-01, -7.8332e-01, -1.6052e+00, -3.0077e-01,\n",
              "          9.0483e-01,  7.7059e-01,  1.0463e-01, -7.8184e-01,  1.1115e+00,\n",
              "          8.8682e-01,  3.0296e-01,  2.4693e-01, -4.3024e-01,  4.9717e-01,\n",
              "         -2.0377e+00, -1.9375e+00, -7.0187e-01, -3.2261e-01,  5.4445e-01,\n",
              "          1.1141e-01, -7.0363e-01]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#########################\n",
        "# POSITIONAL 'ENCODING' #\n",
        "#########################"
      ],
      "metadata": {
        "id": "uEBhtYKQONlj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "postional_embedding = nn.Embedding(num_embeddings=5, embedding_dim=32)"
      ],
      "metadata": {
        "id": "dHmnOaSVPmeS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "postional_embedding(torch.arange(5)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24mQLBiyReS5",
        "outputId": "4c3d7488-f6b4-44f1-efc3-5eac784d573b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_tensor = embedding(t) + postional_embedding(torch.arange(5, dtype=torch.long))\n",
        "embedded_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnBn3VO3RnEw",
        "outputId": "19e1779e-28d6-4408-ff30-f1e860b2f9d5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.4031,  1.5242, -1.4711, -1.4731, -2.3746,  0.7424, -1.4808, -0.6002,\n",
              "          0.4449,  0.2017,  0.2811, -1.3812, -0.1261, -2.4049,  0.5560,  0.0561,\n",
              "         -1.4717,  2.7740,  1.2857, -0.4726,  0.8303, -0.3711, -0.5518, -0.1830,\n",
              "         -0.8156,  1.4427,  0.6201,  1.3365,  0.2396,  1.0576, -0.7943, -0.5432],\n",
              "        [ 0.3579, -0.9022, -2.4643, -1.0618, -4.4340,  1.0900,  1.1752, -0.3345,\n",
              "          2.4141,  0.3887, -0.9735, -0.8638, -0.8206, -0.5100,  0.1251,  0.6341,\n",
              "         -0.2691, -0.1135, -1.0485,  0.6256,  2.8587,  0.3859, -1.0955, -1.3121,\n",
              "         -1.0247, -0.9247, -1.5952, -0.8083,  0.7482, -1.4537,  0.1571, -1.3824],\n",
              "        [ 0.9586,  1.1592, -0.3475,  1.7701,  1.8518, -0.5691, -0.9678, -2.2441,\n",
              "         -0.7347, -0.6185,  0.3041,  0.1427, -0.1808, -0.0668, -0.8789, -1.6833,\n",
              "          2.0690,  1.9846,  0.3055,  0.1877, -0.1492, -1.0446, -1.5930,  0.8403,\n",
              "          0.3971, -3.0851,  3.0781,  0.0779, -2.3419,  0.7785,  0.1147,  1.9837],\n",
              "        [-0.8560, -0.4435,  1.9186, -1.6952, -1.0030, -0.9656, -4.1688,  0.8350,\n",
              "         -0.5218,  1.0746,  0.7658,  1.2187, -0.1280,  1.9157,  0.1032,  0.0629,\n",
              "         -0.2045, -2.5495, -2.0326, -0.2141,  0.4142, -2.8366,  1.9484,  1.1229,\n",
              "         -0.5692,  1.3994, -1.6553,  0.5851, -0.5069, -3.7556,  1.7262,  0.9777],\n",
              "        [ 0.2796, -1.4847,  2.2262,  3.5251,  1.1353, -3.2517, -0.1227,  0.1865,\n",
              "         -0.0743, -0.0992, -0.7206, -0.3520, -0.8097, -2.3663, -1.4969, -1.5023,\n",
              "         -0.1900,  0.4626,  0.0498,  1.4476, -0.1628, -1.0525, -0.3486, -0.5824,\n",
              "         -0.1881, -2.1151, -2.2769,  0.5871, -0.0093,  1.0216, -0.8096, -1.4537]],\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#########################\n",
        "# SINGLE HEAD ATTENTION #\n",
        "#########################"
      ],
      "metadata": {
        "id": "kVyuxDh5Rwvo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# since its not MultiHeadAttention input_dim == output_dim\n",
        "block_size = len(t) if t is not None else block_size\n",
        "\n",
        "key_layer = nn.Linear(in_features=embedding_dim, out_features=embedding_dim)\n",
        "query_layer = nn.Linear(in_features=embedding_dim, out_features=embedding_dim)\n",
        "value_layer = nn.Linear(in_features=embedding_dim, out_features=embedding_dim)\n",
        "tril = torch.tril(torch.ones(block_size, block_size, dtype=torch.long))"
      ],
      "metadata": {
        "id": "CLdJKYDZm7cP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = key_layer(embedded_tensor)\n",
        "q = query_layer(embedded_tensor)\n",
        "wei = (q @ k.transpose(-2,-1)) / (embedding_dim ** -0.5)\n",
        "wei = wei.masked_fill(tril == 0, -float(\"inf\"))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "v = value_layer(embedded_tensor)\n",
        "\n",
        "out = wei @ v\n",
        "wei, out"
      ],
      "metadata": {
        "id": "3WSinYAipzEh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6e89e3a-130e-446a-efc7-e4844a0180f2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "         [1.0000e+00, 3.4261e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "         [7.7772e-07, 1.2493e-27, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "         [5.5852e-10, 1.0000e+00, 2.5168e-21, 9.0518e-31, 0.0000e+00],\n",
              "         [5.1570e-16, 1.6237e-16, 1.0000e+00, 1.7578e-06, 8.7914e-12]],\n",
              "        grad_fn=<SoftmaxBackward0>),\n",
              " tensor([[-0.0947, -0.4619, -1.0668, -0.3539,  0.5693,  0.7228, -1.8971,  0.0692,\n",
              "           1.0132, -0.1141, -0.1005,  0.1660, -0.4363,  0.1858, -0.2616,  0.0830,\n",
              "           0.4446, -0.7536, -0.4261,  0.7051, -0.3212, -0.4210,  0.0957,  1.3890,\n",
              "           0.0606,  0.6657,  0.7420, -0.5712, -0.3385, -0.5723,  0.7971, -0.4750],\n",
              "         [-0.0947, -0.4619, -1.0668, -0.3539,  0.5693,  0.7228, -1.8971,  0.0692,\n",
              "           1.0132, -0.1141, -0.1005,  0.1660, -0.4363,  0.1858, -0.2616,  0.0830,\n",
              "           0.4446, -0.7536, -0.4261,  0.7051, -0.3212, -0.4210,  0.0957,  1.3890,\n",
              "           0.0606,  0.6657,  0.7420, -0.5712, -0.3385, -0.5723,  0.7971, -0.4750],\n",
              "         [-0.3894,  0.3114, -1.3576,  0.6144,  1.3029, -0.2972, -1.1189, -0.3456,\n",
              "          -0.6918,  0.6535, -0.3323, -0.0704, -1.7578,  0.2871, -0.3796,  1.4263,\n",
              "           0.5829, -0.3698,  0.1219,  0.3641, -0.8244, -0.5265,  0.4600,  0.9715,\n",
              "          -0.0720, -0.7194, -0.0642,  1.2260,  0.6956,  0.1970,  0.8301, -0.4768],\n",
              "         [ 0.0886, -0.2615,  0.1184, -1.2103, -0.0128,  0.1052, -0.0820, -0.1690,\n",
              "           0.4250, -0.7879, -0.9183,  0.3432,  0.0970, -0.2803,  0.2149, -0.3047,\n",
              "          -0.2410, -0.9379, -1.7300,  0.2804, -0.3525, -0.4239,  0.3339,  0.3611,\n",
              "          -0.3234,  0.3420,  0.3986, -1.5343,  0.2613, -0.6384,  0.1833, -0.2982],\n",
              "         [-0.3894,  0.3114, -1.3576,  0.6144,  1.3029, -0.2972, -1.1189, -0.3456,\n",
              "          -0.6918,  0.6535, -0.3323, -0.0704, -1.7578,  0.2871, -0.3796,  1.4263,\n",
              "           0.5829, -0.3698,  0.1219,  0.3641, -0.8244, -0.5265,  0.4600,  0.9715,\n",
              "          -0.0720, -0.7194, -0.0642,  1.2260,  0.6956,  0.1970,  0.8301, -0.4768]],\n",
              "        grad_fn=<MmBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########################\n",
        "# MULTI HEAD ATTENTION #\n",
        "########################"
      ],
      "metadata": {
        "id": "-JTijNAxr3l3"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionHead(nn.Module):\n",
        "\n",
        "  def __init__(self, embedding_dim, head_size):\n",
        "    super().__init__()\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.query_layer = nn.Linear(in_features=embedding_dim, out_features=head_size)\n",
        "    self.key_layer = nn.Linear(in_features=embedding_dim, out_features=head_size)\n",
        "    self.value_layer = nn.Linear(in_features=embedding_dim, out_features=head_size)\n",
        "    self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size, dtype=torch.long)))\n",
        "\n",
        "  def forward(self, x):\n",
        "    B, T, C = x.shape\n",
        "    q = self.query_layer(x)\n",
        "    k = self.key_layer(x)\n",
        "    v = self.value_layer(x)\n",
        "    wei = (q @ k.transpose(-2,-1)) / C ** -0.5\n",
        "    wei = wei.masked_fill(self.tril == 0, float(\"-inf\"))\n",
        "    wei = F.softmax(wei, dim=-1)\n",
        "    out = wei @ v\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "HM_aXT9Er7lP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "  def __init__(self, embedding_dim, n_heads):\n",
        "    super().__init__()\n",
        "    head_size = embedding_dim // n_heads\n",
        "    self.heads = nn.ModuleList([AttentionHead(embedding_dim=embedding_dim, head_size=head_size) for _ in range(n_heads)])\n",
        "    self.projection_layer = nn.Linear(in_features=embedding_dim, out_features=embedding_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = torch.cat([head(x) for head in self.heads], dim=-1)\n",
        "    out = self.projection_layer(x)\n",
        "    return out"
      ],
      "metadata": {
        "id": "X_0YzYwJvHs9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_tensor = embedded_tensor.unsqueeze(0)\n",
        "embedded_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igleMpjk2won",
        "outputId": "e23efc61-306f-4223-ebae-636341dd75b9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multi_head_attention = MultiHeadAttention(embedding_dim=embedding_dim, n_heads=n_heads)\n",
        "t_ma = multi_head_attention(embedded_tensor)\n",
        "t_ma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrrWxTzt1VkU",
        "outputId": "ca7d7534-0212-4067-dcf7-c2f34a6a0bc5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-3.3058e-01,  1.5609e-01,  6.0706e-01,  3.7778e-01,  2.2100e-02,\n",
              "           1.7917e-02, -2.2404e-01, -1.8024e-01,  2.8647e-01, -3.9880e-01,\n",
              "          -7.2126e-02, -2.7563e-01, -3.9359e-01,  2.0978e-01,  2.2150e-01,\n",
              "          -4.3236e-01,  1.8456e-01,  1.7068e-01,  1.4273e-01,  4.8865e-01,\n",
              "          -2.2285e-01, -3.8417e-01, -4.9840e-01, -3.3975e-01, -2.6650e-02,\n",
              "          -9.8114e-02,  1.9251e-03, -4.4611e-01, -3.1706e-01,  4.2815e-01,\n",
              "           8.0081e-02,  1.5024e-01],\n",
              "         [-2.7230e-01,  4.2659e-01,  4.8545e-01, -2.8686e-01,  4.2604e-01,\n",
              "           6.0631e-01, -5.2107e-01,  4.6679e-01, -1.9142e-01, -5.8465e-01,\n",
              "          -2.1072e-01,  2.5014e-01, -6.6826e-02, -9.9127e-03,  2.3967e-01,\n",
              "          -1.6353e-01,  2.7169e-01,  5.9880e-02, -1.1598e-01,  4.3161e-01,\n",
              "           2.9813e-01, -8.5463e-01, -2.6795e-01, -1.8554e-01, -2.0781e-01,\n",
              "           9.8717e-02, -1.2805e-01, -6.6290e-01, -4.2944e-01,  4.5616e-01,\n",
              "          -1.3259e-01,  7.4801e-01],\n",
              "         [-1.3898e-01, -1.5688e-01,  6.3180e-01,  8.3651e-02,  6.3392e-01,\n",
              "          -2.8081e-01,  6.6602e-01, -3.0311e-01,  3.6907e-01, -6.9217e-01,\n",
              "          -2.3651e-01,  3.6184e-01,  2.4659e-01, -3.8854e-01,  5.0646e-01,\n",
              "           8.9994e-01,  7.7432e-01, -2.9045e-01,  3.1200e-01, -2.4389e-01,\n",
              "          -4.7172e-01, -1.3647e-02,  3.1212e-02, -5.6781e-02,  1.3067e-02,\n",
              "          -1.1611e+00, -5.1766e-01,  3.7458e-01, -6.5434e-01,  7.9082e-01,\n",
              "          -2.3990e-01, -1.0440e-03],\n",
              "         [ 5.2012e-02,  3.0406e-01, -8.0800e-01, -2.5321e-01,  1.2072e-01,\n",
              "           4.1249e-02, -7.8374e-02,  4.3669e-01, -9.4283e-01, -7.4479e-01,\n",
              "           7.8272e-01, -1.0415e+00,  4.9345e-01,  4.6536e-01,  2.0678e-02,\n",
              "           9.0491e-01,  1.0686e+00,  5.1128e-01,  4.2387e-01,  7.2582e-01,\n",
              "           6.4128e-02,  7.9059e-03,  4.8731e-01,  4.8014e-01,  8.4843e-01,\n",
              "          -7.9687e-01,  5.7956e-01, -3.6589e-01, -1.7146e-01,  1.2956e-01,\n",
              "          -2.7489e-01,  6.8525e-01],\n",
              "         [ 3.4342e-02,  7.0814e-01,  2.9099e-01, -4.2651e-01,  6.0111e-01,\n",
              "          -3.7645e-01,  5.8774e-01, -2.0884e-01,  1.5174e-01,  1.5131e-02,\n",
              "          -3.7529e-02,  4.0093e-01,  2.7005e-01, -6.8598e-02,  3.4443e-01,\n",
              "           1.1844e+00,  1.2132e+00,  6.4232e-02,  1.0593e+00,  3.4976e-01,\n",
              "           1.7253e-01, -9.7619e-02,  4.1477e-01,  1.6801e-01,  4.7429e-01,\n",
              "          -1.1558e+00,  1.7865e-01,  5.7160e-01,  3.0731e-02,  6.1697e-01,\n",
              "           3.2109e-01,  5.0888e-01]]], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################\n",
        "# FEED FORWARD #\n",
        "################"
      ],
      "metadata": {
        "id": "F0lyArs6Nw2b"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feed_forward_layer = nn.Sequential(\n",
        "    nn.Linear(32, 4 * 32),\n",
        "    nn.Linear(4 * 32, 32)\n",
        ")\n",
        "\n",
        "t_ff = feed_forward_layer(t_ma)\n",
        "t_ff"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2O12cNbmN5Mc",
        "outputId": "38126ac6-a1c3-4cae-e853-539072698090"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1047,  0.1062,  0.1296,  0.1487,  0.0168, -0.0017,  0.1265,\n",
              "          -0.0800,  0.0205,  0.0741,  0.0610, -0.0471,  0.0959, -0.2016,\n",
              "           0.1497,  0.0997,  0.1914,  0.0814, -0.1831,  0.1698,  0.2157,\n",
              "           0.1279, -0.1241,  0.0661, -0.1072,  0.0110,  0.1009,  0.1230,\n",
              "           0.0199, -0.0581, -0.0990, -0.0433],\n",
              "         [ 0.0775,  0.0821,  0.2429, -0.0842, -0.0789, -0.1661,  0.3810,\n",
              "          -0.0154, -0.2219,  0.2125,  0.0796, -0.0068, -0.0079, -0.3919,\n",
              "           0.2658,  0.0450,  0.1625, -0.0895, -0.3173,  0.0266,  0.2420,\n",
              "           0.0774, -0.1415, -0.0360, -0.1784,  0.0830,  0.1682, -0.0670,\n",
              "          -0.0937,  0.0481, -0.0330, -0.0315],\n",
              "         [-0.1755, -0.2030, -0.1351, -0.2008,  0.0319, -0.1532,  0.2315,\n",
              "           0.1163,  0.0887,  0.3876,  0.0439, -0.0806, -0.0839, -0.2843,\n",
              "          -0.1508, -0.0357,  0.1185, -0.0181, -0.2770,  0.1237,  0.2894,\n",
              "          -0.0960, -0.0279,  0.0806,  0.1171, -0.0997, -0.0392,  0.0041,\n",
              "          -0.2928,  0.0316, -0.0272, -0.2827],\n",
              "         [ 0.1994,  0.0098, -0.1732, -0.0830,  0.0075, -0.4270,  0.0457,\n",
              "          -0.1096,  0.1317,  0.5453, -0.2313, -0.1543, -0.1294, -0.1406,\n",
              "           0.0386,  0.2654, -0.1507, -0.0682, -0.0738,  0.2639,  0.1543,\n",
              "          -0.1404, -0.3768,  0.2617, -0.2775, -0.2529,  0.2223,  0.1484,\n",
              "           0.0369,  0.0879, -0.1039,  0.5473],\n",
              "         [-0.0776, -0.2309, -0.1338, -0.0680,  0.1491, -0.2300,  0.1939,\n",
              "           0.1059,  0.0865,  0.4971, -0.0232, -0.0557,  0.0482, -0.0458,\n",
              "          -0.0409,  0.0221, -0.1275, -0.1860, -0.1499,  0.3466,  0.1836,\n",
              "          -0.2015, -0.1156,  0.3000,  0.0104,  0.0089,  0.2379, -0.0346,\n",
              "          -0.1539,  0.0970, -0.1078, -0.0712]]], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#############\n",
        "# (LM) HEAD #\n",
        "#############"
      ],
      "metadata": {
        "id": "y7sfUzouQVjD"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm_head = nn.Linear(in_features=embedding_dim, out_features=vocab_size)\n",
        "logits = lm_head(t_ff)\n",
        "logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_U-pPfXQkDl",
        "outputId": "682e620e-be5c-4f0b-abd7-ca7255196c32"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.5506e-02, -6.6762e-02, -1.3066e-01,  6.5135e-02, -8.3698e-02,\n",
              "          -5.1504e-02, -2.2719e-02,  1.6913e-01,  9.2439e-02,  2.4152e-02,\n",
              "           1.6284e-01,  1.7046e-01, -4.5121e-02, -2.1280e-01,  9.1107e-02,\n",
              "           1.7170e-01, -1.5197e-01,  2.9426e-01,  3.6097e-02, -3.9573e-02,\n",
              "           2.5146e-01, -1.5428e-01, -1.7070e-01,  1.6593e-01,  7.0708e-02,\n",
              "          -2.3348e-01,  4.0852e-03,  7.5131e-02,  3.8520e-02,  1.1388e-01,\n",
              "          -1.0648e-01,  8.9193e-02, -9.9233e-02, -2.7843e-02,  2.6298e-01,\n",
              "          -9.9775e-02,  6.4700e-02, -1.0298e-01,  1.4936e-01, -2.0188e-01,\n",
              "           4.6250e-02, -8.0165e-02,  1.6471e-01,  9.2624e-02, -1.2229e-01,\n",
              "           6.5251e-02,  7.2498e-03, -6.6246e-02,  1.7682e-01, -8.3913e-02,\n",
              "          -6.7174e-02,  2.1854e-01, -1.4159e-01,  3.4919e-02,  5.0368e-02,\n",
              "          -1.3656e-01,  1.5915e-01,  1.1124e-01,  1.2764e-01,  3.8893e-02,\n",
              "          -6.7495e-02, -1.9108e-01, -1.3154e-02,  1.1746e-02,  1.5909e-01],\n",
              "         [-6.5415e-02, -1.5212e-01, -1.3857e-01,  9.0228e-02, -1.1278e-01,\n",
              "          -6.8368e-02,  9.0299e-03,  2.7567e-01,  5.9067e-02, -8.1330e-02,\n",
              "           2.1409e-01,  2.6503e-01, -1.8150e-01, -2.3682e-01,  2.0195e-01,\n",
              "           1.2930e-01, -9.9040e-02,  3.2263e-01,  9.0092e-02, -8.5621e-02,\n",
              "           2.3719e-01, -2.2218e-01, -1.3725e-01,  2.4644e-01,  2.3820e-01,\n",
              "          -2.7403e-01, -1.1851e-02,  2.7292e-02,  1.3772e-01,  2.0884e-01,\n",
              "          -8.2843e-02,  3.8249e-02, -6.4300e-02, -1.3082e-01,  2.6769e-01,\n",
              "          -7.2722e-02,  5.2084e-02, -4.0337e-02,  1.9922e-01, -2.4021e-01,\n",
              "          -1.1867e-02, -2.5980e-02,  2.0116e-01,  4.9368e-02, -2.1063e-01,\n",
              "           1.2085e-02,  1.1049e-01,  4.1246e-03,  1.4051e-01, -4.0226e-02,\n",
              "          -3.5257e-02,  1.3648e-01, -1.3174e-02,  3.7043e-02, -5.2043e-02,\n",
              "          -1.6200e-01,  7.4174e-02,  2.4635e-02,  2.6346e-01, -7.0206e-02,\n",
              "          -1.3150e-02, -7.8136e-02, -7.7184e-02, -7.5736e-02,  1.7552e-01],\n",
              "         [ 8.4399e-03, -1.2957e-01, -1.6123e-01,  1.7678e-01, -1.4895e-02,\n",
              "          -2.7807e-02,  1.0327e-01,  1.8973e-01,  1.6206e-01, -1.0675e-01,\n",
              "           1.7808e-01,  2.6818e-01, -2.5072e-01, -2.9049e-02,  1.5824e-01,\n",
              "           1.0781e-01, -1.5678e-01,  2.3599e-01,  1.7690e-02, -6.8008e-02,\n",
              "           1.1781e-01, -3.7543e-02, -1.6085e-03,  1.5823e-01,  3.2464e-02,\n",
              "          -1.3486e-01, -3.0704e-02,  9.6564e-02,  1.1374e-01,  5.4708e-02,\n",
              "          -5.3915e-02,  6.1138e-02, -7.2187e-02, -3.5611e-02,  2.9140e-01,\n",
              "          -3.3915e-05,  1.6153e-01, -8.8196e-02,  2.0051e-01, -2.4757e-01,\n",
              "           5.8283e-02,  1.7365e-02,  6.3816e-02,  1.0203e-01, -1.0574e-01,\n",
              "           1.6792e-01,  3.8548e-02,  8.5027e-02,  1.9985e-01, -2.9174e-01,\n",
              "          -9.7594e-02,  1.0780e-01,  1.0979e-02,  7.7147e-02, -3.7837e-02,\n",
              "          -9.2526e-02,  1.4370e-01, -3.4589e-02,  3.8817e-01,  2.3344e-03,\n",
              "          -1.1326e-01,  8.4354e-03,  1.5152e-02,  1.2735e-03,  3.8628e-02],\n",
              "         [ 8.9834e-02, -1.3521e-01, -1.5286e-01,  3.3636e-02, -3.7293e-02,\n",
              "          -5.3479e-02,  1.1240e-01,  2.8374e-01,  1.8340e-01, -8.5362e-02,\n",
              "           1.1429e-01,  1.0601e-01, -2.8012e-01, -9.4576e-02,  4.7470e-02,\n",
              "           1.4036e-01, -2.2381e-02, -4.9054e-03, -2.7693e-01, -5.0716e-02,\n",
              "           3.8826e-01, -9.0578e-02, -6.3880e-02,  7.3697e-02,  7.7564e-02,\n",
              "          -5.7042e-01,  8.9581e-02,  8.8403e-02,  1.1151e-01,  2.2562e-01,\n",
              "          -1.6162e-01,  5.2988e-02,  2.2025e-01, -3.0258e-01,  4.1210e-01,\n",
              "          -2.6640e-01, -8.1809e-02, -1.3209e-01,  8.3034e-02, -7.1756e-02,\n",
              "          -9.8821e-02, -2.3594e-01, -7.7902e-02, -2.0969e-02, -4.9081e-02,\n",
              "           1.2682e-01,  4.4256e-02,  1.1241e-01,  1.7420e-01, -7.4717e-02,\n",
              "          -1.4625e-01,  1.8234e-01,  1.2103e-01, -9.7627e-02, -9.8577e-02,\n",
              "          -2.3621e-02,  1.2502e-01,  6.0071e-02,  2.7900e-01, -1.1089e-01,\n",
              "           1.5587e-01, -1.2147e-01,  4.4409e-02,  1.1151e-01,  2.8109e-01],\n",
              "         [ 1.4379e-01, -1.8410e-01, -2.6464e-01,  1.8054e-02,  1.3274e-01,\n",
              "          -6.1328e-02,  1.3884e-01,  1.7451e-01,  1.9922e-01, -3.3002e-03,\n",
              "           2.3297e-01,  1.2841e-01, -2.4594e-01, -6.1129e-02,  6.0525e-02,\n",
              "           4.5053e-02, -1.3228e-01,  1.1765e-01, -4.1409e-02, -6.8543e-02,\n",
              "           1.7479e-01, -2.5615e-02, -7.3077e-03, -1.4081e-03,  3.0985e-02,\n",
              "          -2.1986e-01,  8.4524e-02,  9.7374e-02,  1.1282e-01,  1.4055e-01,\n",
              "          -7.8895e-02,  9.9083e-02,  2.2138e-02, -1.5870e-01,  2.1444e-01,\n",
              "          -1.4904e-01,  8.7952e-02, -9.5736e-02,  1.2278e-01, -1.8311e-01,\n",
              "          -2.1048e-02, -1.3952e-01, -8.1000e-02,  1.2095e-01, -6.8229e-02,\n",
              "           1.6086e-01,  3.9050e-02,  2.9660e-02,  1.6154e-01, -1.3678e-01,\n",
              "          -1.4786e-01,  1.9480e-01, -2.9647e-02,  5.1868e-02, -3.9372e-02,\n",
              "          -1.0195e-01,  1.8538e-01,  4.5947e-02,  3.4496e-01, -6.4300e-02,\n",
              "          -2.4749e-02, -5.3327e-02,  2.8050e-02,  2.5188e-02,  1.8502e-01]]],\n",
              "       grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###########\n",
        "# Softmax #\n",
        "###########"
      ],
      "metadata": {
        "id": "thcq_pd9Uer-"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = F.softmax(logits[:, -1, :], dim=-1)\n",
        "encoded_token = torch.argmax(probs)\n",
        "probs, encoded_token\n",
        "decode([encoded_token.item()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sy3HSPqwUhff",
        "outputId": "a0645452-9548-4df3-9d33-d043a9097b5d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'t'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decode([58])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "i2cbIXbfV05q",
        "outputId": "5d14b9dc-fffb-48ca-aa26-7fbfb6a530b3"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'t'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = torch.ones(4,8,3)\n",
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaYbte54hzQK",
        "outputId": "af48721c-d656-4240-c196-3e373f6794c5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(test, dim=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1TgNWpXsgvf",
        "outputId": "ad9beae7-8c07-47c9-be13-5315964da0ac"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3., 3., 3., 3., 3., 3., 3., 3.],\n",
              "        [3., 3., 3., 3., 3., 3., 3., 3.],\n",
              "        [3., 3., 3., 3., 3., 3., 3., 3.],\n",
              "        [3., 3., 3., 3., 3., 3., 3., 3.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R6ziYO3ksk1k"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}