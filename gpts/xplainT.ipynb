{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2Fmx9sk0skqcHlwzRyLtB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/G0nkly/pytorch_sandbox/blob/main/gpts/xplainT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "-knMob-ZM-1V"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdzsO4TKNFLB",
        "outputId": "b35f7291-3713-4f91-c2dd-199ee5b6f00e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-04 16:18:32--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.009s  \n",
            "\n",
            "2025-07-04 16:18:33 (116 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(mode=\"r\", file=\"input.txt\") as f:\n",
        "  text = f.read()\n",
        "\n",
        "text[:1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "AAt04Vx-O4Ri",
        "outputId": "354b5767-13bb-402f-e8d3-ea9ff2ee38e0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you know Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us kill him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be done: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citizens, the patricians good.\\nWhat authority surfeits on would relieve us: if they\\nwould yield us but the superfluity, while it were\\nwholesome, we might guess they relieved us humanely;\\nbut they think we are too dear: the leanness that\\nafflicts us, the object of our misery, is as an\\ninventory to particularise their abundance; our\\nsufferance is a gain to them Let us revenge this with\\nour pikes, ere we become rakes: for the gods know I\\nspeak this in hunger for bread, not in thirst for revenge.\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(list(text)))"
      ],
      "metadata": {
        "id": "YwHfhC4GO-Ra"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {v : k for k, v in enumerate(vocab)}\n",
        "itos = {k : v for k, v in enumerate(vocab)}\n",
        "\n",
        "encode = lambda seq : [stoi[s] for s in seq]\n",
        "decode = lambda idx : \"\".join([itos[x] for x in idx])"
      ],
      "metadata": {
        "id": "r4JfpdA5SoLI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.tensor(encode(text))"
      ],
      "metadata": {
        "id": "v4VBhSu_X1LT"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###################\n",
        "# HYPERPARAMETERS #\n",
        "###################\n",
        "embed_dim = 32\n",
        "block_size = 8"
      ],
      "metadata": {
        "id": "xJcZNvD4VH_7"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = nn.Embedding(embed_dim, embed_dim)"
      ],
      "metadata": {
        "id": "WXdWRf4VaV5G"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding(torch.randint(3, (1,2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6TSVi-0aaLg",
        "outputId": "6e516f5f-b231-4f05-909f-cb01149f7a18"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.0869e+00,  7.8041e-02,  7.9894e-01,  1.0715e+00,  9.5654e-01,\n",
              "           7.6049e-01,  1.7241e-01,  4.7712e-01,  4.1163e-01, -1.7514e+00,\n",
              "          -4.7344e-01, -2.0426e+00,  3.2502e-01,  2.1115e+00,  9.8810e-01,\n",
              "           9.5602e-01, -4.8398e-01, -1.0437e+00,  2.2327e-01, -2.7945e-01,\n",
              "           4.7489e-01, -5.9326e-01,  1.8130e-01, -1.9923e+00,  8.7360e-01,\n",
              "           4.6991e-02, -7.4626e-01,  1.2625e+00,  8.5126e-01,  1.5300e+00,\n",
              "           1.5616e+00, -2.7176e-01],\n",
              "         [ 1.7934e+00, -2.0259e+00, -2.1625e-01,  8.7295e-01, -3.0981e-01,\n",
              "          -1.2320e+00, -1.5905e-02, -1.0086e+00,  1.9879e+00, -1.0159e+00,\n",
              "           1.1537e+00,  2.4487e+00, -2.1411e-01,  2.1464e+00, -5.1017e-01,\n",
              "          -2.1689e-01,  2.7450e+00, -1.1084e+00, -3.4781e-01, -5.8417e-01,\n",
              "           4.7171e-01,  3.7252e-01, -1.0554e+00,  1.1568e+00, -1.2528e-01,\n",
              "          -4.2954e-01, -8.9155e-01, -1.8819e+00, -7.0897e-01, -1.3370e+00,\n",
              "          -8.6959e-01,  2.7468e-04]]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mp5GkjZbbTJ7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}